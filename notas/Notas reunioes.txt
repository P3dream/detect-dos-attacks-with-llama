Trabalho implementado anteriormente:
Arquitetura: 2 Maquinas virtuais LUbuntu e um pc 1 real windows.

1 Servidora 
1 Atacante
1 Pc real windows com o modelo llama.

Cenario: A maquina atacante roda scripts conhecidos como golden eye etc... e na maquina servidora, esses pacotes sao capturados usando tshark,
esses pacotes sao enviados por rede interna ao pc real que analisa esses pacotes usando um modelo llama3.1.

Posteriormente a ideia e fazer um finetuning para analisar se melhorou ou piorou usando o LoRa.

Foi encontrado o dataset CICDataset que possui dados sobre diferentes tipos de ataque DoS. 

E entao seria interessante pois poderia fazer testes do modelo com fluxos de dados ja rotulados, e inclusive treinar ele.


Notas reuniÃ£o 10 Setembro 2025, Valladolid

Fine tuning do modelo - Treinar usando LoRa (Treina uma camada a mais, ao inves de treinar todo o modelo)


Dataset para ser utilizado - http://cicresearch.ca/CICDataset/CICDDoS2019/Dataset/
Informacoes sobre o dataset - https://www.unb.ca/cic/datasets/ddos-2019.html


Notas 18 Setembro 2025, Valladolid

O dataset tem informacoes por fluxo e nao por pacotes como estava sendo capturado.

Fluxo de pacotes: sequÃªncia de pacotes de rede entre dois endpoints que compartilham IP de origem, IP de destino, portas e protocolo.

Em vez de analisar pacotes individuais, o fluxo resume o trÃ¡fego com mÃ©tricas como:

- inÃ­cio e fim do fluxo
- nÃºmero de pacotes
- total e tamanho mÃ©dio de bytes
- taxa de pacotes e bytes por segundo
- mÃ©dia e desvio do intervalo entre pacotes

Vantagem: reduz dados e permite analisar o comportamento geral da comunicaÃ§Ã£o, Ãºtil para detecÃ§Ã£o de ataques e monitoramento de rede.


Entao agora vou testar se funciona essa abordagem de fluxo. Fazer uma adaptacao no que esperava pacotes, para esperar fluxos.

Servidor e agentes adaptados para uma versao de fluxo.

Agora eu tenho que extrair aquele csv, e testar o llama, poderia fazer um fluxo que teste o desempenho atual com o dataset e ver como ele se saiu.

Isso ja seria interessante para fazer uma analise.

4734 / 191694 â‰ˆ 0.0247 â†’ 2.47% - Benign (%)
186960 / 191694 â‰ˆ 0.9753 â†’ 97.53% - Portmap (%)


Notas 19/11/2025, Valladolid

Testei o modelo llama padrao sem treinamento e os resultados estao em portmap, a matriz de confusao.

Agora o proximo passo seria treinar o modelo usando LoRa.

Pelo que vi, se treinarmos com lora separando em treinamento, validacao e teste, vamos gerar um novo arquivo com os pesos
do treinamento, e para usar o modelo treinado temos 2 opcoes:

Usando ollama, teria que fazer a uniao desses pesos lora com o modelo llama 8GB, o que nao seria bom porque teria que
ter varios modelos treinados de 8gb.

Ou transformers que seria melhor porque eu poderia "encaixar" os pesos em um modelo generico.

Vou treinar o modelo com 200 amostras, 50% de cada classe para validar meu fluxo e vamos ver se ja podemos ver alguma
pequena melhora.

====================================================================================================================================

Notas avanÃ§os dia 25-11-2025

ðŸ“Œ CorrelaÃ§Ã£o das variÃ¡veis numÃ©ricas:
                             Total Length of Fwd Packets  \
Total Length of Fwd Packets                     1.000000   
Bwd Packet Length Max                           0.405263   
Flow Bytes/s                                   -0.025296   => variavel independente
FIN Flag Count                                       NaN   => Variavel fin flag count descartada
Fwd IAT Total                                   0.356497   
Bwd IAT Total                                   0.384744   

